---
phase: 02-run-unit-metering
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - core/graph.py
  - orchestrator/orchestrator_service.py
  - shared/observability/metrics.py
autonomous: true

must_haves:
  truths:
    - "Every tool execution in _tools_node records run units in UsageStore"
    - "Quota is checked before _process_query begins computation"
    - "gRPC RESOURCE_EXHAUSTED returned when quota exceeded"
    - "nexus_run_units_total Prometheus counter incremented per tool call"
    - "Run-unit recording does not block tool execution (fail-open on metering error)"
    - "Org_id flows from AgentState into usage records"
  artifacts:
    - path: "core/graph.py"
      provides: "Run-unit instrumentation in _tools_node"
      contains: "run_unit_calculator"
    - path: "orchestrator/orchestrator_service.py"
      provides: "Quota check before query processing"
      contains: "quota_manager.check_quota"
    - path: "shared/observability/metrics.py"
      provides: "RunUnitMetrics dataclass and create_run_unit_metrics factory"
      contains: "class RunUnitMetrics"
  key_links:
    - from: "core/graph.py"
      to: "shared/billing/run_units.py"
      via: "calculates run units per tool execution"
      pattern: "run_unit_calculator.calculate_from_latency"
    - from: "core/graph.py"
      to: "shared/billing/usage_store.py"
      via: "records run units after each tool call"
      pattern: "usage_store.record"
    - from: "orchestrator/orchestrator_service.py"
      to: "shared/billing/quota_manager.py"
      via: "checks quota before processing query"
      pattern: "quota_manager.check_quota"
    - from: "shared/observability/metrics.py"
      to: "OpenTelemetry meter"
      via: "creates nexus_run_units_total counter"
      pattern: "nexus_run_units_total"
---

<objective>
Wire run-unit metering into the core execution pipeline: instrument _tools_node for per-call recording, add quota enforcement before _process_query, and export Prometheus counters.

Purpose: Without this wiring, the billing package from Plan 01 sits unused. After this plan, every tool call is metered, quota is enforced, and Prometheus can visualize run-unit consumption.
Output: Modified core/graph.py, orchestrator_service.py, and metrics.py with metering instrumentation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-run-unit-metering/02-RESEARCH.md
@.planning/phases/02-run-unit-metering/02-01-PLAN.md
@core/graph.py
@orchestrator/orchestrator_service.py
@shared/observability/metrics.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add RunUnitMetrics to observability</name>
  <files>shared/observability/metrics.py</files>
  <action>
**shared/observability/metrics.py modifications:**

1. Add `RunUnitMetrics` dataclass after existing metric dataclasses:
```python
@dataclass
class RunUnitMetrics:
    """Metrics for run-unit metering."""
    # Total run units consumed by org, tier, and tool
    run_units_total: Counter
    # Run units per request histogram
    run_units_per_request: Histogram
```

2. Add `create_run_unit_metrics()` factory function following existing pattern:
```python
def create_run_unit_metrics(meter: Optional[Meter] = None) -> RunUnitMetrics:
    m = meter or get_meter()
    run_units_total = m.create_counter(
        name="nexus_run_units_total",
        description="Total run units consumed",
        unit="1",
    )
    run_units_per_request = m.create_histogram(
        name="nexus_run_units_per_request",
        description="Run units consumed per request",
        unit="1",
    )
    return RunUnitMetrics(
        run_units_total=run_units_total,
        run_units_per_request=run_units_per_request,
    )
```

3. Add `RunUnitMetrics` and `create_run_unit_metrics` to `shared/observability/__init__.py` exports.
  </action>
  <verify>
Run: `cd /Users/sertanavdan/Documents/Software/AI/gRPC_llm && python -c "from shared.observability.metrics import RunUnitMetrics, create_run_unit_metrics; m = create_run_unit_metrics(); print(f'RunUnitMetrics created: {type(m.run_units_total).__name__}'); print('RunUnitMetrics OK')"`
  </verify>
  <done>
RunUnitMetrics dataclass and factory function added to observability. nexus_run_units_total counter and nexus_run_units_per_request histogram ready for use.
  </done>
</task>

<task type="auto">
  <name>Task 2: Instrument _tools_node with run-unit recording</name>
  <files>core/graph.py</files>
  <action>
**core/graph.py modifications:**

1. Add imports at top of file:
```python
from shared.billing.run_units import RunUnitCalculator
from shared.billing.usage_store import UsageStore
```

2. In the `NexusGraph.__init__()` method, initialize billing components:
```python
# Billing / metering
self._run_unit_calculator = RunUnitCalculator()
self._usage_store = UsageStore(db_path=os.getenv("BILLING_DB_PATH", "data/billing.db"))
```

3. In the `_tools_node` method, AFTER the existing latency calculation and result recording block (after `results.append(execution_result.to_dict())`), add run-unit recording:
```python
# --- Run-unit metering ---
try:
    cpu_seconds = latency_ms / 1000.0
    tier = state.get("model_tier", "standard")
    run_units = self._run_unit_calculator.calculate_from_latency(
        latency_ms=latency_ms,
        tier=tier,
        tool_name=tool_name,
    )
    org_id = state.get("org_id") or "default"
    self._usage_store.record(
        org_id=org_id,
        tool_name=tool_name,
        run_units=run_units,
        tier=tier,
        user_id=state.get("user_id"),
        thread_id=state.get("conversation_id"),
        cpu_seconds=cpu_seconds,
        latency_ms=latency_ms,
    )
except Exception as metering_err:
    # Fail-open: metering errors must not block tool execution
    logger.warning(f"Run-unit metering failed for {tool_name}: {metering_err}")
```

IMPORTANT: This block must be inside the `for tool_call in tool_calls:` loop, after the latency calculation. It must be wrapped in try/except to fail-open â€” a metering failure should never block a tool execution.

4. After the tool_calls loop (outside the for loop), add aggregate run-unit tracking to state:
```python
# Track cumulative run units for this request
request_run_units = state.get("request_run_units", 0.0)
# Sum run units from this batch of tool calls
for r in results:
    request_run_units += r.get("run_units", 0.0)
```
And include `request_run_units` in the returned state update.

Note: To include run_units in results, modify the `execution_result` dict creation or add it separately. Simplest approach: compute run_units before creating `execution_result` and add to the dict:
```python
execution_result_dict = execution_result.to_dict()
execution_result_dict["run_units"] = run_units
results.append(execution_result_dict)
```
(Replace the existing `results.append(execution_result.to_dict())` line.)
  </action>
  <verify>
Run: `cd /Users/sertanavdan/Documents/Software/AI/gRPC_llm && python -c "
from shared.billing.run_units import RunUnitCalculator
from shared.billing.usage_store import UsageStore
# Verify imports work in graph context
calc = RunUnitCalculator()
ru = calc.calculate_from_latency(latency_ms=250.0, tier='standard', tool_name='default')
print(f'Run units for 250ms standard tool: {ru}')
assert ru > 0
print('Graph billing imports OK')
"`
  </verify>
  <done>
Every tool execution in _tools_node now computes and records run units. Recording is fail-open (errors logged but don't block tool execution). Org_id flows from AgentState into usage records. Run units tracked per tool call in results.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add quota enforcement to orchestrator</name>
  <files>orchestrator/orchestrator_service.py</files>
  <action>
**orchestrator/orchestrator_service.py modifications:**

1. Add imports at top:
```python
from shared.billing.quota_manager import QuotaManager
from shared.billing.usage_store import UsageStore
```

2. In `OrchestratorService.__init__()`, initialize billing components:
```python
# Billing / metering
self._usage_store = UsageStore(db_path=os.getenv("BILLING_DB_PATH", "data/billing.db"))
self._quota_manager = QuotaManager(usage_store=self._usage_store)
```

3. In `_process_query()`, ADD quota check at the start, after intent analysis but before any LIDM routing or graph invocation:
```python
# --- Quota enforcement ---
org_id = "default"  # TODO: extract from request context when gRPC metadata carries auth
try:
    quota_result = self._quota_manager.check_quota(org_id)
    if not quota_result.allowed:
        logger.warning(f"Quota exceeded for org={org_id}: {quota_result.current_usage}/{quota_result.limit}")
        return {
            "content": f"Usage quota exceeded. You have used {quota_result.current_usage:.1f} of {quota_result.limit:.1f} run units this month. Please upgrade your plan or wait until next billing period.",
            "messages": [],
            "tool_results": [],
            "iteration": 0,
            "quota_exceeded": True,
        }
except Exception as quota_err:
    # Fail-open: quota check errors should not block queries
    logger.warning(f"Quota check failed: {quota_err}")
```

Place this block AFTER the intent_analysis / needs_clarification check and BEFORE the LIDM routing block. This ensures we reject over-quota requests before spending any compute.

4. Also add the run-unit metrics counter increment. In `__init__`, after existing metrics initialization:
```python
from shared.observability.metrics import create_run_unit_metrics, RunUnitMetrics
self._run_unit_metrics: Optional[RunUnitMetrics] = None
if self.observability_enabled:
    self._run_unit_metrics = create_run_unit_metrics()
```
  </action>
  <verify>
Run: `cd /Users/sertanavdan/Documents/Software/AI/gRPC_llm && python -c "
from shared.billing.quota_manager import QuotaManager
from shared.billing.usage_store import UsageStore
# Verify orchestrator billing imports work
store = UsageStore(db_path='/tmp/test_orch_billing.db')
qm = QuotaManager(usage_store=store)
result = qm.check_quota('default', plan='free')
print(f'Quota check: allowed={result.allowed}, remaining={result.remaining}')
assert result.allowed
print('Orchestrator billing imports OK')
import os; os.remove('/tmp/test_orch_billing.db')
"`
  </verify>
  <done>
Quota check runs before any compute in _process_query. Over-quota requests return a clear message without spending compute. Fail-open on quota check errors. RunUnitMetrics initialized for Prometheus export.
  </done>
</task>

</tasks>

<verification>
- `_tools_node` records run units for every tool call (verify by inspecting billing.db after a tool execution)
- `_process_query` rejects requests when org quota is exceeded
- `nexus_run_units_total` counter exists in OTel metrics
- Metering failures don't block tool execution (fail-open pattern verified)
- Quota failures don't block the system (fail-open on quota check errors)
</verification>

<success_criteria>
- Every tool call in _tools_node calculates and persists run units
- Quota enforcement blocks over-limit orgs BEFORE compute starts
- Prometheus counter nexus_run_units_total tracks usage per org/tier/tool
- All metering code is fail-open (try/except with warning log, never blocks)
- Run units flow from AgentState.org_id to usage_records.org_id
</success_criteria>

<output>
After completion, create `.planning/phases/02-run-unit-metering/02-02-SUMMARY.md`
</output>
