---
phase: 06-ux-visual-expansion
plan: 04
type: execute
wave: 3
depends_on: [06-02, 06-03]
files_modified:
  - ui_service/src/app/monitoring/page.tsx
  - ui_service/src/lib/errors.ts
  - ui_service/src/components/ui/error-states.tsx
  - shared/auth/user_prefs.py
  - orchestrator/admin_api.py
  - ui_service/src/hooks/useUserPrefs.ts
  - ui_service/src/components/nav/Navbar.tsx
  - ui_service/src/app/layout.tsx
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Monitoring page displays service health cards from GET /admin/feature-health"
    - "Monitoring page shows P99/P95/P50 latency per active service"
    - "Error taxonomy with 5 error types maps to visible error states across all pages"
    - "DegradedBanner, EmptyState, TimeoutSkeleton components exist and handle errors visually"
    - "User preferences persist across page refreshes via SQLite backend"
    - "Navigation reflects all 6 page routes: dashboard, modules, finance, monitoring, pipeline, settings"
    - "All pages wrap data fetches with error taxonomy mapping — no silent failures"
  artifacts:
    - path: "ui_service/src/app/monitoring/page.tsx"
      provides: "Monitoring page with service health cards, agent runs table, P99/P95/P50 latency display, Grafana embed tabs"
      min_lines: 100
    - path: "ui_service/src/lib/errors.ts"
      provides: "Error taxonomy: NOT_AUTHORIZED, NOT_CONFIGURED, DEGRADED_PROVIDER, TOOL_SCHEMA_MISMATCH, TIMEOUT with mapping functions"
      exports: ["NexusErrorType", "classifyError", "isRetryable"]
      min_lines: 40
    - path: "ui_service/src/components/ui/error-states.tsx"
      provides: "Error state components: DegradedBanner, EmptyState, TimeoutSkeleton for consistent error UX"
      exports: ["DegradedBanner", "EmptyState", "TimeoutSkeleton"]
      min_lines: 60
    - path: "shared/auth/user_prefs.py"
      provides: "SQLite user_prefs table with optimistic concurrency, CRUD functions"
      exports: ["UserPrefsStore", "UserPreferences"]
      min_lines: 60
    - path: "ui_service/src/hooks/useUserPrefs.ts"
      provides: "React hook for reading/writing user preferences with optimistic updates"
      exports: ["useUserPrefs"]
      min_lines: 40
  key_links:
    - from: "ui_service/src/app/monitoring/page.tsx"
      to: "ui_service/src/hooks/useCapabilities.ts"
      via: "uses capability envelope for feature health display"
      pattern: "useCapabilities\\(\\)"
    - from: "ui_service/src/app/monitoring/page.tsx"
      to: "ui_service/src/lib/adminClient.ts"
      via: "fetches feature health and latency data"
      pattern: "adminClient\\.getFeatureHealth"
    - from: "ui_service/src/lib/errors.ts"
      to: "ui_service/src/components/ui/error-states.tsx"
      via: "error types drive component selection"
      pattern: "NexusErrorType"
    - from: "orchestrator/admin_api.py"
      to: "shared/auth/user_prefs.py"
      via: "user prefs GET/PUT endpoints use UserPrefsStore"
      pattern: "user_prefs_store"
---

<objective>
Build monitoring page with P99 observability, standardized error taxonomy + UI components, user preference persistence, and navigation updates for the complete page structure.

Purpose: Monitoring currently shows 92 lines of basic stats. Error handling across pages is inconsistent — some fail silently, others crash. User preferences don't persist. Navigation doesn't reflect the full page structure. This plan completes the UX layer with monitoring depth, consistent error UX, preference persistence, and unified navigation.

Output: Monitoring page with P99 latency, error taxonomy + 3 error state components, user prefs SQLite backend + React hook, updated navigation for all 6 pages.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary-minimal.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-ux-visual-expansion/06-CONTEXT.md
@.planning/phases/06-ux-visual-expansion/06-02-SUMMARY.md
@.planning/phases/06-ux-visual-expansion/06-03-SUMMARY.md

Academic anchors:
- Event-Driven Microservice Orchestration Principles: §6.1 (1.2s event-to-action latency target, P99 benchmarks), §5.1 (resilience theme T1 — failure-mode-pattern fit)
- Agentic Builder-Tester Pattern: §5 (agent monitoring — observability for build runs, repair attempts)

@ui_service/src/app/monitoring/page.tsx
@ui_service/src/components/nav/Navbar.tsx
@ui_service/src/app/layout.tsx
@data/verify_snapshot.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Monitoring page rewrite with P99 observability</name>
  <files>ui_service/src/app/monitoring/page.tsx</files>
  <action>
    **v0 Prompt** (generate visual shell):
    ```
    Create a Next.js 14 monitoring dashboard page with shadcn/ui and Tailwind. Sections:

    1. Service Health Grid (top): Cards for each service (Orchestrator, Dashboard, UI, LLM Gateway, Sandbox, ChromaDB, Bridge). Each card shows: service name, status dot (green/amber/red), uptime percentage, last health check time.

    2. Latency Panel (middle): Three-column layout showing P50, P95, P99 latency for each active service. Values in milliseconds with color coding: green < 200ms, amber < 500ms, red > 500ms. Target line at 500ms for P99.

    3. Agent Runs Table (bottom left, 2/3 width): Table with columns: Build ID, Module, Stage (scaffold/implement/test/repair), Status (success/failed/in-progress), Duration, Attempts. Last 20 runs. Clickable rows for detail.

    4. Grafana Embed (bottom right, 1/3 width): Tab group with "Overview", "Modules", "Alerts" tabs. Each tab contains an iframe to Grafana dashboard panel.

    Use Card, Table, Tabs, Badge from shadcn/ui. Dark mode support.
    ```

    **Cursor wiring**:
    - Import `useCapabilities()` for feature health data and adapter status
    - Service health cards: derive from `envelope.features` + direct health check endpoints
    - Latency data: read from `data/verify_snapshot.json` (Phase 4 latency snapshot) via API endpoint, OR fetch from Prometheus if available
    - P50/P95/P99 display with color coding: green < 200ms, amber < 500ms, red >= 500ms
    - P99 target: highlight any service exceeding 500ms P99 with red badge + "Above Target" label
    - Agent runs table: fetch from orchestrator metrics endpoint or admin API (list recent build jobs)
    - Grafana tabs: use existing Grafana URLs from Docker Compose (`http://localhost:3000/d/...`)
    - Error handling: wrap all data fetches with `classifyError()` from error taxonomy (Task 2)
    - Loading states: skeleton cards + table placeholder
  </action>
  <verify>
    `wc -l ui_service/src/app/monitoring/page.tsx | awk '{print $1}'` >= 100.
    `pnpm --filter ui_service build` — succeeds.
    Monitoring page renders service health cards and latency data when navigated to.
  </verify>
  <done>
    Monitoring page shows service health, P99/P95/P50 latency per service with target line, agent runs table, and Grafana embed tabs. P99 target violations highlighted.
  </done>
</task>

<task type="auto">
  <name>Task 2: Error taxonomy + error state components + user preferences</name>
  <files>ui_service/src/lib/errors.ts, ui_service/src/components/ui/error-states.tsx, shared/auth/user_prefs.py, orchestrator/admin_api.py, ui_service/src/hooks/useUserPrefs.ts</files>
  <action>
    Create `ui_service/src/lib/errors.ts`:
    - `NexusErrorType` enum: `NOT_AUTHORIZED`, `NOT_CONFIGURED`, `DEGRADED_PROVIDER`, `TOOL_SCHEMA_MISMATCH`, `TIMEOUT`
    - `classifyError(error: unknown): NexusErrorType` — maps HTTP status codes and error shapes:
      - 401/403 → NOT_AUTHORIZED
      - 404 on provider/adapter + missing config → NOT_CONFIGURED
      - 502/503 on provider endpoint → DEGRADED_PROVIDER
      - JSON parse error or unexpected response shape → TOOL_SCHEMA_MISMATCH
      - Timeout / AbortError → TIMEOUT
    - `isRetryable(type: NexusErrorType): boolean` — TIMEOUT and DEGRADED_PROVIDER are retryable; others are not
    - `errorMessage(type: NexusErrorType): string` — user-friendly message for each type

    Create `ui_service/src/components/ui/error-states.tsx`:
    - `DegradedBanner`: amber banner with warning icon, message, and optional "Retry" button. Shows when a feature is DEGRADED. Props: `feature: string`, `reasons: string[]`, `onRetry?: () => void`
    - `EmptyState`: centered illustration placeholder + message + optional action button. Shows when no data available (module list empty, no transactions). Props: `title: string`, `description: string`, `action?: { label: string, onClick: () => void }`
    - `TimeoutSkeleton`: skeleton UI with a "Taking longer than usual..." overlay after 5s timeout. Shows during slow data fetches. Props: `children: ReactNode` (the skeleton layout)
    - All components use shadcn/ui primitives (Alert, Skeleton, Button)

    Create `shared/auth/user_prefs.py`:
    - `UserPreferences` Pydantic model: `theme: str` (light/dark/system), `provider_ordering: list[str]`, `module_favorites: list[str]`, `monitoring_tab: str` (overview/modules/alerts), `dashboard_layout: dict | None`
    - `UserPrefsStore` class: SQLite `user_prefs` table with columns (user_id TEXT PK, prefs_json TEXT, version INTEGER, updated_at TEXT)
    - `get_prefs(user_id: str) -> UserPreferences` — returns defaults if no record exists
    - `set_prefs(user_id: str, prefs: UserPreferences, expected_version: int) -> int` — optimistic concurrency check: if stored version != expected_version, raise ConflictError. Returns new version.
    - WAL-mode SQLite (consistent with other stores)

    Add endpoints to `orchestrator/admin_api.py`:
    - `GET /admin/user/prefs` — returns user's preferences + current version. User derived from auth context.
    - `PUT /admin/user/prefs` — accepts `{ prefs: UserPreferences, version: int }`, applies optimistic concurrency, returns updated prefs + new version. On conflict: returns 409 with current server state.

    Create `ui_service/src/hooks/useUserPrefs.ts`:
    - React hook returning `{ prefs: UserPreferences, updatePrefs: (partial: Partial<UserPreferences>) => void, isLoading: boolean, isSaving: boolean }`
    - On mount: fetch prefs from `GET /admin/user/prefs`
    - `updatePrefs()`: optimistic update (apply locally first), then `PUT /admin/user/prefs`. On 409 conflict: re-fetch server state and merge.
    - Store version in ref for concurrency tracking
  </action>
  <verify>
    `python -c "from shared.auth.user_prefs import UserPrefsStore, UserPreferences; print('ok')"` succeeds.
    `npx tsc --noEmit ui_service/src/lib/errors.ts ui_service/src/components/ui/error-states.tsx ui_service/src/hooks/useUserPrefs.ts` — no type errors.
    `grep -n "NOT_AUTHORIZED\|DEGRADED_PROVIDER\|TIMEOUT" ui_service/src/lib/errors.ts | wc -l` >= 3.
    `grep -n "DegradedBanner\|EmptyState\|TimeoutSkeleton" ui_service/src/components/ui/error-states.tsx | wc -l` >= 3.
  </verify>
  <done>
    Error taxonomy with 5 types + 3 error state components ready for use across all pages. User preferences persist via SQLite with optimistic concurrency. GET/PUT /admin/user/prefs endpoints wired.
  </done>
</task>

<task type="auto">
  <name>Task 3: Navigation update + full QA pass</name>
  <files>ui_service/src/components/nav/Navbar.tsx, ui_service/src/app/layout.tsx</files>
  <action>
    Update `ui_service/src/components/nav/Navbar.tsx`:
    - Navigation links for all 6 pages:
      - Dashboard (/) — home/overview
      - Modules (/modules) — module browser with lifecycle panel
      - Finance (/finance) — financial data + charts
      - Monitoring (/monitoring) — service health + P99 + agent runs
      - Pipeline (/pipeline) — build job viewer (existing, not rewritten in this phase)
      - Settings (/settings/providers) — provider configuration with lock/unlock
    - Active page highlighting based on current route
    - Responsive: hamburger menu on mobile, sidebar or horizontal nav on desktop
    - Optional: user preference for nav collapsed/expanded (if useUserPrefs available)

    Update `ui_service/src/app/layout.tsx`:
    - Ensure Navbar is rendered in layout for all pages
    - Wrap children with error boundary that uses `classifyError()` and renders `DegradedBanner` on unhandled errors
    - Include user preference provider context if needed

    Full QA verification to close Phase 6:
    - Navigate to each of the 6 pages and confirm rendering
    - Verify error states display correctly (disconnect an adapter → DegradedBanner appears)
    - Verify data source indicator on dashboard (Live/Mock/Offline)
    - Verify finance lock/unlock gating
    - Verify monitoring P99 display
    - Verify chat action cards appear for tool calls
    - Run `make verify` — all existing tests pass with zero regressions
    - P99 latency target: all active service endpoints respond < 500ms at p99 (from verify_snapshot.json)
  </action>
  <verify>
    `grep -n "Dashboard\|Modules\|Finance\|Monitoring\|Pipeline\|Settings" ui_service/src/components/nav/Navbar.tsx | wc -l` >= 6.
    `pnpm --filter ui_service build` — succeeds.
    `make verify` — all tests pass.
    All 6 pages accessible via navigation and render without errors.
  </verify>
  <done>
    Navigation updated for all 6 pages. Error taxonomy applied across all pages. User preferences persist. All pages render from capability contract. P99 target met. make verify passes.
  </done>
</task>

</tasks>

<verification>
- `pnpm --filter ui_service build` — succeeds
- `make verify` — all tests pass
- Monitoring page shows P99/P95/P50 latency per service
- Error state components (DegradedBanner, EmptyState, TimeoutSkeleton) render correctly
- User preferences persist across page refreshes
- Navigation includes all 6 page routes
- P99 latency < 500ms for all active services
</verification>

<success_criteria>
- Monitoring page provides complete observability: health cards, latency percentiles, agent runs, Grafana tabs
- Error taxonomy standardizes error handling across all pages — no silent failures
- User preferences persist via SQLite with optimistic concurrency
- Navigation reflects full page structure
- All pages render from capability contract data
- make verify passes with zero regressions
- P99 latency target met (< 500ms) for all active service endpoints
</success_criteria>

<output>
After completion, create `.planning/phases/06-ux-visual-expansion/06-04-SUMMARY.md`
</output>
