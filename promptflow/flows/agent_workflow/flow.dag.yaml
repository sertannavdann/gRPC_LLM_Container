# Agent Workflow - Main orchestration flow
# This mirrors the orchestrator service logic using Prompt Flow DAG
$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt

inputs:
  user_query:
    type: string
    description: The user's input query
  debug_mode:
    type: bool
    default: false
    description: Enable debug output
  max_iterations:
    type: int
    default: 5
    description: Maximum tool calling iterations

outputs:
  final_answer:
    type: string
    reference: ${synthesize_response.output}
  tools_used:
    type: string
    reference: ${tool_executor.tools_called}
  context_used:
    type: string
    reference: ${context_retriever.context}

nodes:
  # Step 1: Analyze intent and determine required tools
  - name: intent_analyzer
    type: python
    source:
      type: code
      path: intent_analyzer.py
    inputs:
      query: ${inputs.user_query}
    
  # Step 2: Retrieve relevant context from ChromaDB
  - name: context_retriever
    type: python
    source:
      type: code
      path: context_retriever.py
    inputs:
      query: ${inputs.user_query}
      intent: ${intent_analyzer.output}
  
  # Step 3: Select and prepare tools based on intent
  - name: tool_selector
    type: llm
    source:
      type: code
      path: tool_selector.jinja2
    inputs:
      query: ${inputs.user_query}
      intent: ${intent_analyzer.output}
      available_tools: ${intent_analyzer.available_tools}
    connection: openai_connection
    api: chat
    parameters:
      model: gpt-4o-mini
      temperature: 0.1
      max_tokens: 500
      response_format:
        type: json_object

  # Step 4: Execute selected tools
  - name: tool_executor
    type: python
    source:
      type: code
      path: tool_executor.py
    inputs:
      tool_selection: ${tool_selector.output}
      query: ${inputs.user_query}
      max_iterations: ${inputs.max_iterations}

  # Step 5: Synthesize final response
  - name: synthesize_response
    type: llm
    source:
      type: code
      path: synthesize_response.jinja2
    inputs:
      query: ${inputs.user_query}
      context: ${context_retriever.context}
      tool_results: ${tool_executor.results}
      debug_mode: ${inputs.debug_mode}
    connection: openai_connection
    api: chat
    parameters:
      model: gpt-4o-mini
      temperature: 0.7
      max_tokens: 1024
